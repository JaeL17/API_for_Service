{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8bfef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from modelhelper import (\n",
    "    init_logger,\n",
    "    ModelHelper\n",
    ")\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "class ClassificationHelper():\n",
    "    def __init__(self, args):\n",
    "        args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "\n",
    "        model_helper = ModelHelper()\n",
    "        dict_modelset = model_helper.get_modelset(args.model_type)\n",
    "\n",
    "        tokenizer = dict_modelset['tokenizer'].from_pretrained(\n",
    "            args.model_name_or_path,\n",
    "            do_lower_case=args.do_lower_case\n",
    "        )        \n",
    "        config = dict_modelset['config'].from_pretrained(args.model_name_or_path)   \n",
    "        # self.model = dict_modelset['model'].from_pretrained(args.model_name_or_path)\n",
    "        \n",
    "        self.model = dict_modelset['model'](config)\n",
    "        # print(self.model)\n",
    "        self.model.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"pytorch_model.bin\")))\n",
    "                \n",
    "        self.model.to(args.device)\n",
    "        self.model_id2label = config.id2label\n",
    "        self.model_label2id = {_label:_id for _id, _label in config.id2label.items()}\n",
    "        self.args = args\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "    def classifyList_decoding(self, list_text, top_n=3, decode_seq_len=5):\n",
    "        list_result = []\n",
    "        \n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(text_data, None) for text_data in list_text],\n",
    "            max_length=self.args.max_seq_len,\n",
    "            padding=\"max_length\",\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        \n",
    "        all_input_ids = torch.tensor([e for e in batch_encoding['input_ids']], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([e for e in batch_encoding['attention_mask']], dtype=torch.long)     \n",
    "        all_token_type_ids = torch.tensor([e for e in batch_encoding['token_type_ids']], dtype=torch.long)\n",
    "        all_decoder_inputs = torch.tensor([self.model_label2id.get('#') for _ in range(len(batch_encoding['input_ids']))], dtype=torch.long)\n",
    "\n",
    "        tensor_dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_decoder_inputs)\n",
    "        sequence_sampler = SequentialSampler(tensor_dataset)\n",
    "        dataloader = DataLoader(tensor_dataset, sampler=sequence_sampler, batch_size=self.args.eval_batch_size)\n",
    "\n",
    "        for batch in dataloader:\n",
    "            self.model.eval()\n",
    "            batch = tuple(t.to(self.args.device) for t in batch)\n",
    "            \n",
    "            list_logits, list_preds = [], []\n",
    "            with torch.no_grad():\n",
    "                inputs_1 = {\n",
    "                    \"encoder_input_ids\": batch[0],                \n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                }\n",
    "                encoder_out = self.model.encode(**inputs_1)\n",
    "                \n",
    "                batch_size = batch[0].shape[0]\n",
    "                decoder_hidden_states = None\n",
    "                temp_input_ids = batch[3].view(-1, 1)\n",
    "                feed_tensor = torch.unsqueeze(encoder_out[:, 0, :], 1)\n",
    "                \n",
    "                for i in range(self.args.decode_seq_len):\n",
    "                    inputs_2 = {\n",
    "                        \"encoder_out\": encoder_out,\n",
    "                        \"decoder_input_ids\": temp_input_ids,\n",
    "                        \"decoder_feeds\":feed_tensor, # [batch_size, 1, hidden_size],\n",
    "                        \"decoder_hidden_states\": decoder_hidden_states\n",
    "                    }\n",
    "                    logits, decoder_hidden_states, feed_tensor = self.model.decode(**inputs_2)\n",
    "\n",
    "                    temp_logits = torch.nn.functional.softmax(logits, dim=2) # [batch_size, decoder_seqlen, num_labels]\n",
    "                    temp_preds = torch.argmax(logits, dim=2) # [batch_size, decoder_seqlen]\n",
    "\n",
    "                    list_logits.append(temp_logits[:,-1, :])\n",
    "                    list_preds.append(torch.unsqueeze(temp_preds[:,-1], 1))\n",
    "\n",
    "                    temp_input_ids = temp_preds[:,-1].view(-1, 1)\n",
    "                    \n",
    "            total_logits = torch.cat(list_logits, dim=1)\n",
    "            total_pred = torch.cat(list_preds, dim=1)\n",
    "            \n",
    "            np_logits = total_logits.detach().cpu().numpy().reshape(-1, decode_seq_len, len(self.model_id2label))\n",
    "            np_preds = np.argsort(np_logits, axis=2)\n",
    "            \n",
    "            topn_pred = np_preds[:,:,-top_n:]\n",
    "            topn_prob = np.take_along_axis(np_logits, topn_pred, axis=2)\n",
    "\n",
    "            for list_pred, list_prob in zip(topn_pred, topn_prob):\n",
    "                dict_result = {}\n",
    "                temp_pred = ''\n",
    "                for decode_idx in range(decode_seq_len):\n",
    "                    list_pred_ele = list_pred[decode_idx]\n",
    "                    list_prob_ele = list_prob[decode_idx]     \n",
    "                    print(f\"list_pred_ele : {list_pred_ele}\")\n",
    "                    print(f\"list_prob_ele : {list_prob_ele}\")\n",
    "                    for cnt, (_pred, _prob) in enumerate(zip(list_pred_ele, list_prob_ele)):\n",
    "                        #print(f\"pred1:  {_pred}\")\n",
    "                        _pred = self.model_id2label.get(int(_pred))\n",
    "                        #print(f\"pred2:  {_pred}\")\n",
    "                        topn_idx = top_n-cnt\n",
    "                        print(f'{decode_idx+1}_{topn_idx}_pred : {_pred}')\n",
    "                        dict_result.update({f'{decode_idx+1}_{topn_idx}_pred':temp_pred + str(_pred), f'{decode_idx+1}_{topn_idx}_prob':str(_prob)})\n",
    "                    \n",
    "                    temp_pred = temp_pred + str(list_pred_ele[0])\n",
    "                    #temp_pred = temp_pred + str(_pred)\n",
    "                list_result.append(dict_result)\n",
    "\n",
    "        return list_result  # [{'1_pred':'', '1_prob':'', '2_pred':'', '2_prob':''}, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc06dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from attrdict import AttrDict\n",
    "\n",
    "from modelhelper import (\n",
    "    init_logger,\n",
    "    ModelHelper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "346a36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--input_file\", type=str, default=\"\")\n",
    "parser.add_argument(\"--output_file\", type=str, default=\"\")\n",
    "parser.add_argument(\"--top_n\", type=int, default=3)\n",
    "parser.add_argument(\"--decode_seq_len\", type=int, default=5)\n",
    "\n",
    "parser.add_argument(\"--write_mode\", type=int, default=2)\n",
    "\n",
    "parser.add_argument(\"--buff_size\", type=int, default=1024)\n",
    "\n",
    "# parser.add_argument(\"--task\", type=str, default=\"\")\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"bert_generation\")\n",
    "parser.add_argument(\"--model_name_or_path\", type=str, default=\"/docker/model_results/v_c/patent_bert_large_generation_v_c/checkpoint-271852\")\n",
    "\n",
    "parser.add_argument(\"--max_seq_len\", type=int, default=512)\n",
    "parser.add_argument(\"--eval_batch_size\", type=int, default=32)\n",
    "\n",
    "parser.add_argument(\"--do_lower_case\", action='store_true', help=\"\")\n",
    "parser.add_argument(\"--no_cuda\", action='store_true', help=\"\")\n",
    "\n",
    "parser.add_argument(\"--label_embedding\", action='store_true', help=\"\")\n",
    "parser.add_argument(\"--multiclass\", action='store_true', help=\"\")    \n",
    "parser.add_argument(\"--do_infer\", action='store_true', help=\"\")\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e29e4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_helper = ClassificationHelper(args)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b50eb017",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp_text = [\"A pulse generator (1) that generates a signal by the rotation of the head drum in a video recorder that includes a rotating head drum partially wrapped by a magnetic tape. A frequency converter 6 is used to change the frequency of the signal generated by the pulse generator within a predetermined value range. In order to correct the head exchange time point, a generator (3) for generating a pulse corresponding to the frequency converted signal is generated. A memory 4 for storing signals generated by the generator is generated by the generator. The record features that the signal generated by the pulse generator 1 is changed by the generator 3 in the process of adjusting the pulse generator 1 to the generator 5, which generates a head-switching signa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29852ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_key = []\n",
    "\n",
    "for i in range(1, args.decode_seq_len+1, 1):\n",
    "    for j in range(1, args.top_n+1, 1):\n",
    "        list_key.append(f'{i}_{j}_pred')\n",
    "        list_key.append(f'{i}_{j}_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8dcf12e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_pred_ele : [7 3 6]\n",
      "list_prob_ele : [6.8900976e-05 1.0151900e-03 9.9887222e-01]\n",
      "1_3_pred\n",
      "1_2_pred\n",
      "1_1_pred\n",
      "list_pred_ele : [ 2  9 10]\n",
      "list_prob_ele : [1.6934413e-04 3.9739185e-03 9.9569017e-01]\n",
      "2_3_pred\n",
      "2_2_pred\n",
      "2_1_pred\n",
      "list_pred_ele : [10  3  2]\n",
      "list_prob_ele : [1.8309740e-06 6.1403756e-05 9.9993551e-01]\n",
      "3_3_pred\n",
      "3_2_pred\n",
      "3_1_pred\n",
      "list_pred_ele : [5 3 2]\n",
      "list_prob_ele : [2.3343149e-05 2.1766005e-02 9.7819978e-01]\n",
      "4_3_pred\n",
      "4_2_pred\n",
      "4_1_pred\n",
      "list_pred_ele : [10  3  2]\n",
      "list_prob_ele : [8.58060594e-06 1.16560095e-05 9.99979138e-01]\n",
      "5_3_pred\n",
      "5_2_pred\n",
      "5_1_pred\n"
     ]
    }
   ],
   "source": [
    "list_temp_result = classification_helper.classifyList_decoding(list_temp_text, args.top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d276acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "result_BUFF = '\\t'.join([list_temp_result[i][key] for key in list_key])\n",
    "result_BUFF2 = [(key, list_temp_result[i][key]) for key in list_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "757d5724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1_1_pred', '5'),\n",
       " ('1_1_prob', '0.9988722'),\n",
       " ('1_2_pred', '2'),\n",
       " ('1_2_prob', '0.00101519'),\n",
       " ('1_3_pred', '6'),\n",
       " ('1_3_prob', '6.8900976e-05'),\n",
       " ('2_1_pred', '59'),\n",
       " ('2_1_prob', '0.99569017'),\n",
       " ('2_2_pred', '58'),\n",
       " ('2_2_prob', '0.0039739185'),\n",
       " ('2_3_pred', '51'),\n",
       " ('2_3_prob', '0.00016934413'),\n",
       " ('3_1_pred', '591'),\n",
       " ('3_1_prob', '0.9999355'),\n",
       " ('3_2_pred', '592'),\n",
       " ('3_2_prob', '6.1403756e-05'),\n",
       " ('3_3_pred', '599'),\n",
       " ('3_3_prob', '1.830974e-06'),\n",
       " ('4_1_pred', '5911'),\n",
       " ('4_1_prob', '0.9781998'),\n",
       " ('4_2_pred', '5912'),\n",
       " ('4_2_prob', '0.021766005'),\n",
       " ('4_3_pred', '5914'),\n",
       " ('4_3_prob', '2.334315e-05'),\n",
       " ('5_1_pred', '59111'),\n",
       " ('5_1_prob', '0.99997914'),\n",
       " ('5_2_pred', '59112'),\n",
       " ('5_2_prob', '1.16560095e-05'),\n",
       " ('5_3_pred', '59119'),\n",
       " ('5_3_prob', '8.580606e-06')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_BUFF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dceb0cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1_1_pred', '5'),\n",
       " ('1_1_prob', '0.9988722'),\n",
       " ('1_2_pred', '2'),\n",
       " ('1_2_prob', '0.00101519'),\n",
       " ('1_3_pred', '6'),\n",
       " ('1_3_prob', '6.8900976e-05'),\n",
       " ('2_1_pred', '79'),\n",
       " ('2_1_prob', '0.99569017'),\n",
       " ('2_2_pred', '78'),\n",
       " ('2_2_prob', '0.0039739185')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_BUFF2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f368a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(1,4):\n",
    "    pred = ''\n",
    "    score = ''\n",
    "    for j in range(1,6):\n",
    "        pred += list_temp_result[0][f\"{j}_{i}_pred\"][-1]\n",
    "    res.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5a554d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '0.9988722',\n",
       " '2',\n",
       " '0.00101519',\n",
       " '6',\n",
       " '6.8900976e-05',\n",
       " '79',\n",
       " '0.99569017',\n",
       " '78',\n",
       " '0.0039739185',\n",
       " '71']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_line[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e11150aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_line =result_BUFF.split('\\t')\n",
    "temp_pred = ''\n",
    "for e in [2, 4, 6, 8, 10]:\n",
    "    temp_pred += sp_line[e][-1]\n",
    "    \n",
    "temp_prob = 1        \n",
    "for e in [3, 5, 7, 9, 11]:\n",
    "    temp_prob = temp_prob * float(sp_line[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "134e883d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26981'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c2d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
